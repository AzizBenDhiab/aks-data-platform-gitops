# Superset configuration overrides
configOverrides:
  secret: |
    import os

    SECRET_KEY = os.environ.get('SUPERSET_SECRET_KEY', 'fallback-secret')

    # Enable CORS for development (restrict in production)
    ENABLE_CORS = True
    CORS_OPTIONS = {
      'supports_credentials': True,
      'allow_headers': ['*'],
      'resources': ['*'],
      'origins': ['http://localhost:8088', 'http://superset.local']
    }

    # Define SQLALCHEMY_DATABASE_URI
    SQLALCHEMY_DATABASE_URI = f"postgresql+psycopg2://{os.environ.get('DB_USER')}:{os.environ.get('DB_PASS')}@{os.environ.get('DB_HOST')}:{os.environ.get('DB_PORT')}/{os.environ.get('DB_NAME')}"

    # --- Important for ingress/proxy ---
    ENABLE_PROXY_FIX = True

    # CSRF handling (needed for login behind ingress)
    WTF_CSRF_ENABLED = True
    WTF_CSRF_EXEMPT_LIST = []
    WTF_CSRF_ALLOWED_ORIGINS = ["http://superset.local", "http://localhost:8088"]

    # Cookie/session handling
    SESSION_COOKIE_SAMESITE = None
    SESSION_COOKIE_SECURE = False

# Global service account for Azure Workload Identity
serviceAccountName: "superset-workload-identity"

# Service account configuration
serviceAccount:
  create: false

# PostgreSQL configuration
postgresql:
  enabled: true
  auth:
    existingSecret: "superset-secrets"
    secretKeys:
      adminPasswordKey: "superset-postgres-password"
      userPasswordKey: "superset-postgres-password"
    database: "superset"
    username: "superset"
  primary:
    persistence:
      enabled: true
      size: 10Gi
      storageClass: "managed-csi"
    resources:
      limits:
        memory: 512Mi
        cpu: 500m
      requests:
        memory: 256Mi
        cpu: 250m
    podLabels:
      azure.workload.identity/use: "true"

# Redis configuration
redis:
  enabled: true
  auth:
    enabled: false
  master:
    persistence:
      enabled: true
      size: 5Gi
      storageClass: "managed-csi"
    resources:
      limits:
        memory: 256Mi
        cpu: 200m
      requests:
        memory: 128Mi
        cpu: 100m

# Global labels for workload identity
extraLabels:
  azure.workload.identity/use: "true"

# Global CSI volume for Key Vault secrets
extraVolumes:
- name: secrets-store
  csi:
    driver: secrets-store.csi.k8s.io
    readOnly: true
    volumeAttributes:
      secretProviderClass: "superset-secrets"
- name: datasources-config
  configMap:
    name: superset-datasources-config

extraVolumeMounts:
- name: secrets-store
  mountPath: "/mnt/secrets-store"
  readOnly: true
- name: datasources-config
  mountPath: "/app/configs"
  readOnly: true

# Extra configs for datasources
extraConfigs:
  import_datasources.yaml: |
    databases:
    - database_name: PostgreSQL Primary
      sqlalchemy_uri: postgresql+psycopg2://superset:${DB_PASS}@apache-superset-postgresql:5432/superset
      extra:
        metadata_params: {}
        engine_params: {}
        metadata_cache_timeout: {}
        schemas_allowed_for_file_upload: []
      allow_run_async: true
      allow_ctas: true
      allow_cvas: true
      allow_dml: true
      allow_multi_schema_metadata_fetch: true
      allow_file_upload: true
      expose_in_sqllab: true
      force_ctas_schema: null
      uuid: 550e8400-e29b-41d4-a716-446655440000

# Superset Node configuration
supersetNode:
  replicaCount: 1
  podLabels:
    azure.workload.identity/use: "true"
  resources:
    limits:
      memory: 1Gi
      cpu: 500m
    requests:
      memory: 512Mi
      cpu: 250m
  command:
  - /bin/sh
  - -c
  - |
    # Set environment variables
    export DB_USER=superset
    export DB_HOST=apache-superset-postgresql
    export DB_PORT=5432
    export DB_NAME=superset
    export DB_PASS=$(cat /mnt/secrets-store/superset-postgres-password)
    export SUPERSET_SECRET_KEY=$(cat /mnt/secrets-store/superset-secret-key)
    # Start Superset
    . {{ .Values.configMountPath }}/superset_bootstrap.sh; gunicorn --bind "0.0.0.0:{{ .Values.service.port }}" --access-logfile '-' --error-logfile '-' --workers 1 --worker-class gthread --threads 20 --timeout 60 --keep-alive 2 --max-requests 1000 --max-requests-jitter 100 --preload "superset.app:create_app()"

# Superset Worker configuration
supersetWorker:
  replicaCount: 1
  podLabels:
    azure.workload.identity/use: "true"
  resources:
    limits:
      memory: 512Mi
      cpu: 250m
    requests:
      memory: 256Mi
      cpu: 125m
  command:
  - /bin/sh
  - -c
  - |
    # Set environment variables
    export DB_USER=superset
    export DB_HOST=apache-superset-postgresql
    export DB_PORT=5432
    export DB_NAME=superset
    export DB_PASS=$(cat /mnt/secrets-store/superset-postgres-password)
    # Start Superset worker
    . {{ .Values.configMountPath }}/superset_bootstrap.sh; celery --app=superset.tasks.celery_app:app worker --pool=gevent --concurrency=20 -l INFO

# Disable Celery Beat
supersetCeleryBeat:
  enabled: false

# Initial setup with admin credentials
init:
  createAdmin: false
  command:
    - /bin/sh
    - -c
    - |
      export SUPERSET_ADMIN_PASSWORD=$(cat /mnt/secrets-store/superset-admin-password)
      export SECRET_KEY=$(cat /mnt/secrets-store/superset-secret-key)
      export DB_PASS=$(cat /mnt/secrets-store/superset-postgres-password)
      . {{ .Values.configMountPath }}/superset_bootstrap.sh
      set -eu
      echo "Upgrading DB schema..."
      superset db upgrade
      echo "Initializing roles..."
      superset init

      echo "Creating admin user..."
      superset fab create-admin \
                      --username admin \
                      --firstname Admin \
                      --lastname User \
                      --email admin@example.com \
                      --password "$SUPERSET_ADMIN_PASSWORD" \
                      || true
      echo "Updating admin user..."
      superset fab reset-password --username admin --password "$SUPERSET_ADMIN_PASSWORD"  

      echo "Loading examples..."
      superset load_examples
      
      # Process datasources template with environment variables
      if [ -f "/app/configs/import_datasources.yaml" ]; then
        echo "Processing datasources template..."
        envsubst < /app/configs/import_datasources.yaml > /tmp/import_datasources_processed.yaml
        echo "Importing database connections.... "
        superset import_datasources -p /tmp/import_datasources_processed.yaml
      fi


service:
  type: ClusterIP
  port: 8088

ingress:
  enabled: false

runAsUser: 1000

bootstrapScript: |
  #!/bin/bash
  pip install --upgrade pip
  pip install --no-cache-dir \
    psycopg2-binary \
    redis \
    flask-cors \
    gevent