# .github/workflows/deploy-aks-data-platform.yml
name: Deploy AKS Data Platform with ArgoCD
on:
  # push:
  #   branches: [main]
  #   paths:
  #     - "terraform/**"
  #     - "k8s/**"
  #     - "argocd/**"
  #     - ".github/workflows/**"
  #     - "manifests/**"
  #     - "values/**"
  # pull_request:
  #   branches: [main]
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to deploy"
        required: true
        default: "dev"
        type: choice
        options:
          - dev
          - staging
          - prod
      resource_group_name:
        description: "Resource Group Name"
        required: true
        default: "rg-aks-data-dev"
        type: string
      location:
        description: "Azure Region"
        required: true
        default: "West Europe"
        type: string
      cluster_name:
        description: "AKS Cluster Name"
        required: true
        default: "aks-data-dev-test"
        type: string
      kubernetes_version:
        description: "Kubernetes Version"
        required: true
        default: "1.32.5"
        type: string
      system_node_count:
        description: "System Node Count"
        required: true
        default: "2"
        type: string
      workload_identity_namespace:
        description: "Workload Identity Namespace"
        required: true
        default: "default"
        type: string
      workload_identity_service_account:
        description: "Workload Identity Service Account"
        required: true
        default: "workload-identity-sa"
        type: string
      keyvaultname:
        description: "Key Vault Name"
        required: true
        default: "kv-aks-data-dev-95548452"
        type: string
      destroy:
        description: "Destroy infrastructure"
        required: false
        default: false
        type: boolean

# Grant GITHUB_TOKEN write permissions for id-token and contents
permissions:
  id-token: write
  contents: read
  pull-requests: write

env:
  # Remove ARM_CLIENT_SECRET - not needed for OIDC
  ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
  ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
  ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
  ARM_USE_OIDC: true
  TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
  TF_VAR_resource_group_name: ${{ github.event.inputs.resource_group_name || 'rg-aks-data-dev' }}
  TF_VAR_location: ${{ github.event.inputs.location || 'West Europe' }}
  TF_VAR_cluster_name: ${{ github.event.inputs.cluster_name || 'aks-data-dev-test' }}
  TF_VAR_kubernetes_version: ${{ github.event.inputs.kubernetes_version || '1.32.5' }}
  TF_VAR_system_node_count: ${{ github.event.inputs.system_node_count || '2' }}
  TF_VAR_subscription_id: ${{ github.event.inputs.subscription_id || 'a6de3cd4-15d9-4c7f-87ac-9a4399b01e45' }}
  TF_VAR_workload_identity_namespace: ${{ github.event.inputs.workload_identity_namespace || 'default' }}
  TF_VAR_workload_identity_service_account: ${{ github.event.inputs.workload_identity_service_account || 'workload-identity-sa' }}
  TF_VAR_keyvaultname: ${{ github.event.inputs.keyvaultname || 'kv-aks-data-dev-95548452' }}

jobs:
  terraform:
    name: "Terraform Plan & Apply"
    runs-on: ubuntu-latest

    outputs:
      cluster_name: ${{ steps.tf-output.outputs.cluster_name }}
      resource_group: ${{ steps.tf-output.outputs.resource_group }}
      keyvault_name: ${{ steps.tf-output.outputs.keyvault_name }}
      azure_client_id: ${{ steps.tf-output.outputs.azure_client_id }}
      azure_tenant_id: ${{ steps.tf-output.outputs.azure_tenant_id }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0
          terraform_wrapper: false

      - name: Azure Login (OIDC)
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Terraform Init
        working-directory: ./terraform
        run: |
          terraform init \
            -backend-config="resource_group_name=${{ secrets.TF_STATE_RG }}" \
            -backend-config="storage_account_name=${{ secrets.TF_STATE_SA }}" \
            -backend-config="container_name=tfstate" \
            -backend-config="key=${{ env.TF_VAR_environment }}.terraform.tfstate"

      - name: Terraform Validate
        working-directory: ./terraform
        run: terraform validate

      - name: Terraform Plan
        working-directory: ./terraform
        run: |
          terraform plan -out=tfplan
          echo "Plan file created: tfplan"

      - name: Terraform Apply
        if: github.ref == 'refs/heads/main'
        working-directory: ./terraform
        run: |
          echo "Applying terraform plan..."
          ls -la tfplan  # Verify plan file exists
          terraform apply -auto-approve tfplan

      - name: Get Terraform Outputs
        if: github.ref == 'refs/heads/main'
        id: tf-output
        working-directory: ./terraform
        run: |
          echo "cluster_name=$(terraform output -raw cluster_name)" >> $GITHUB_OUTPUT
          echo "resource_group=$(terraform output -raw resource_group_name)" >> $GITHUB_OUTPUT
          echo "keyvault_name=$(terraform output -raw keyvault_name)" >> $GITHUB_OUTPUT
          echo "azure_client_id=$(terraform output -raw azure_client_id)" >> $GITHUB_OUTPUT
          echo "azure_tenant_id=$(terraform output -raw azure_tenant_id)" >> $GITHUB_OUTPUT

  generate-keyvault-secrets:
    name: "Generate Key Vault Secrets"
    runs-on: ubuntu-latest
    needs: [terraform]
    if: success()

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Azure Login (OIDC)
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Generate and Store Secrets in Key Vault
        run: |
          # Get Key Vault name from terraform output
          KEYVAULT_NAME="${{ needs.terraform.outputs.keyvault_name }}"

          echo "Using Key Vault: $KEYVAULT_NAME"

          # Generate secure passwords for all applications
          SUPERSET_SECRET_KEY=$(openssl rand -base64 48 | tr -d "=+/" | cut -c1-48)
          SUPERSET_POSTGRES_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)
          SUPERSET_ADMIN_PASSWORD=$(openssl rand -base64 16 | tr -d "=+/" | cut -c1-16)
          NIFI_SENSITIVE_KEY=$(openssl rand -base64 24 | tr -d "=+/" | cut -c1-24)
          NIFI_KEYSTORE_PASSWORD=$(openssl rand -base64 24 | tr -d "=+/" | cut -c1-24)
          NIFI_TRUSTSTORE_PASSWORD=$(openssl rand -base64 24 | tr -d "=+/" | cut -c1-24)
          NIFI_ADMIN_PASSWORD=$(openssl rand -base64 16 | tr -d "=+/" | cut -c1-16)
          KOBO_REDIS_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)
          KOBO_ADMIN_PASSWORD=$(openssl rand -base64 16 | tr -d "=+/" | cut -c1-16)
          KOBO_DJANGO_SECRET=$(openssl rand -base64 48 | tr -d "=+/" | cut -c1-48)
          KOBO_POSTGRES_ADMIN_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)
          KOBO_POSTGRES_USER_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)
          KOBO_MONGO_ROOT_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)
          KOBO_MONGO_USER_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)
          GRAFANA_ADMIN_PASSWORD=$(openssl rand -base64 16 | tr -d "=+/" | cut -c1-16)
          ALERTMANAGER_SECRET=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)
          PROMETHEUS_SECRET=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)

          # Add monitoring secrets to Key Vault
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "grafana-admin-user" --value "admin"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "grafana-admin-password" --value "$GRAFANA_ADMIN_PASSWORD"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "alertmanager-secret" --value "$ALERTMANAGER_SECRET"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "prometheus-secret" --value "$PROMETHEUS_SECRET"

          # Add Joget secrets to Key Vault
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "joget-database" --value "joget"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "joget-username" --value "joget_user"
          # Add Superset secrets
          echo "Adding Superset secrets..."
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "superset-secret-key" --value "$SUPERSET_SECRET_KEY"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "superset-postgres-password" --value "$SUPERSET_POSTGRES_PASSWORD"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "superset-admin-password" --value "$SUPERSET_ADMIN_PASSWORD"

          # Add NiFi secrets
          echo "Adding NiFi secrets..."
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "nifi-sensitive-key" --value "$NIFI_SENSITIVE_KEY"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "nifi-keystore-password" --value "$NIFI_KEYSTORE_PASSWORD"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "nifi-truststore-password" --value "$NIFI_TRUSTSTORE_PASSWORD"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "nifi-admin-password" --value "$NIFI_ADMIN_PASSWORD"

          # Add KoboToolbox secrets
          echo "Adding KoboToolbox secrets..."
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "kobo-redis-password" --value "$KOBO_REDIS_PASSWORD"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "kobo-admin-password" --value "$KOBO_ADMIN_PASSWORD"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "kobo-django-secret" --value "$KOBO_DJANGO_SECRET"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "kobo-postgres-admin-password" --value "$KOBO_POSTGRES_ADMIN_PASSWORD"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "kobo-postgres-user-password" --value "$KOBO_POSTGRES_USER_PASSWORD"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "kobo-mongo-root-password" --value "$KOBO_MONGO_ROOT_PASSWORD"
          az keyvault secret set --vault-name $KEYVAULT_NAME --name "kobo-mongo-user-password" --value "$KOBO_MONGO_USER_PASSWORD"

          echo "All secrets have been stored in Key Vault: $KEYVAULT_NAME"

  setup-argocd:
    name: "Setup ArgoCD"
    runs-on: ubuntu-latest
    needs: [terraform, generate-keyvault-secrets]
    if: success()

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Azure Login (OIDC)
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Get AKS Credentials
        run: |
          az aks get-credentials \
            --resource-group ${{ needs.terraform.outputs.resource_group }} \
            --name ${{ needs.terraform.outputs.cluster_name }} \
            --overwrite-existing

      - name: Create Configuration ConfigMaps
        run: |
          # Get values from terraform outputs
          KEYVAULT_NAME="${{ needs.terraform.outputs.keyvault_name }}"
          AZURE_CLIENT_ID="${{ needs.terraform.outputs.azure_client_id }}"
          AZURE_TENANT_ID="${{ needs.terraform.outputs.azure_tenant_id }}"

          # Create ConfigMaps for each namespace that needs Azure configuration
          namespaces=("superset" "nifi-prod" "monitoring" "kobotoolbox" "postgresql" "joget")

          for ns in "${namespaces[@]}"; do
            echo "Creating ConfigMap for namespace: $ns"
            
            # Create namespace if it doesn't exist
            kubectl create namespace $ns --dry-run=client -o yaml | kubectl apply -f -
            
            # Create ConfigMap with Azure configuration
            kubectl create configmap azure-config \
              --from-literal=AZURE_KEYVAULT_NAME=$KEYVAULT_NAME \
              --from-literal=AZURE_CLIENT_ID=$AZURE_CLIENT_ID \
              --from-literal=AZURE_TENANT_ID=$AZURE_TENANT_ID \
              --namespace=$ns \
              --dry-run=client -o yaml | kubectl apply -f -
          done

          echo "ConfigMaps created successfully"

      - name: Install ArgoCD
        run: |
          # Create ArgoCD namespace
          kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -

          # Install ArgoCD
          kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

          # Wait for ArgoCD to be ready
          kubectl wait --for=condition=available --timeout=600s deployment/argocd-server -n argocd

      - name: Configure ArgoCD
        run: |
          # Get ArgoCD admin password
          ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
          echo "ARGOCD_PASSWORD=$ARGOCD_PASSWORD" >> $GITHUB_ENV

          # Create ArgoCD service LoadBalancer
          kubectl patch svc argocd-server -n argocd -p '{"spec": {"type": "LoadBalancer"}}'

          # Wait for external IP (with timeout and better error handling)
          echo "Waiting for ArgoCD LoadBalancer IP..."
          RETRY_COUNT=0
          MAX_RETRIES=30
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            EXTERNAL_IP=$(kubectl get svc argocd-server -n argocd -o jsonpath="{.status.loadBalancer.ingress[0].ip}" 2>/dev/null || echo "")
            if [[ -n "$EXTERNAL_IP" && "$EXTERNAL_IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
              echo "ArgoCD LoadBalancer IP obtained: $EXTERNAL_IP"
              break
            fi
            echo "Waiting for LoadBalancer IP... (attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)"
            sleep 10
            RETRY_COUNT=$((RETRY_COUNT + 1))
          done
          
          if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
            echo "Failed to get LoadBalancer IP after $MAX_RETRIES attempts"
            kubectl get svc argocd-server -n argocd
            exit 1
          fi

      - name: Deploy Root Application via ArgoCD
        run: |
          # Get ArgoCD server external IP
          ARGOCD_SERVER=$(kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          echo "ArgoCD Server IP: $ARGOCD_SERVER"

          # Install ArgoCD CLI if not already available
          echo "Checking for ArgoCD CLI..."
          
          if command -v argocd &> /dev/null; then
            echo "ArgoCD CLI already installed"
            argocd version --client
          else
            echo "Installing ArgoCD CLI..."
            
            # Download to /tmp directory
            curl -sSL -o /tmp/argocd https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
            
            # Verify download was successful
            if [ ! -f /tmp/argocd ]; then
              echo "Failed to download ArgoCD CLI"
              exit 1
            fi
            
            # Make executable and move to /usr/local/bin
            chmod +x /tmp/argocd
            sudo mv /tmp/argocd /usr/local/bin/argocd
            
            # Verify installation
            argocd version --client
            echo "ArgoCD CLI installed successfully"
          fi
          # Wait for ArgoCD API to be ready
          sleep 30

          # Login to ArgoCD
          argocd login $ARGOCD_SERVER --username admin --password $ARGOCD_PASSWORD --insecure

          # Apply the root application directly via kubectl (more reliable)
          kubectl apply -f - <<EOF
          apiVersion: argoproj.io/v1alpha1
          kind: Application
          metadata:
            name: root-app
            namespace: argocd
          spec:
            project: default
            source:
              repoURL: https://github.com/${{ github.repository }}
              targetRevision: HEAD
              path: argocd/apps
            destination:
              server: https://kubernetes.default.svc
              namespace: argocd
            syncPolicy:
              automated:
                prune: true
                selfHeal: true
          EOF

          # Wait for application to be created and auto-synced
          echo "Waiting for root application to be created and automatically synced..."
          sleep 30
          
          # Check application status and wait for auto-sync to complete
          MAX_WAIT_TIME=300  # 5 minutes
          WAIT_INTERVAL=15   # Check every 15 seconds
          ELAPSED_TIME=0
          
          while [ $ELAPSED_TIME -lt $MAX_WAIT_TIME ]; do
            APP_STATUS=$(argocd app get root-app -o json | jq -r '.status.sync.status' 2>/dev/null || echo "Unknown")
            APP_HEALTH=$(argocd app get root-app -o json | jq -r '.status.health.status' 2>/dev/null || echo "Unknown")
            
            echo "Root app - Sync: $APP_STATUS, Health: $APP_HEALTH (waited ${ELAPSED_TIME}s)"
            
            if [ "$APP_STATUS" = "Synced" ]; then
              echo "Root application successfully auto-synced!"
              break
            fi
            
            sleep $WAIT_INTERVAL
            ELAPSED_TIME=$((ELAPSED_TIME + WAIT_INTERVAL))
          done
          
          if [ $ELAPSED_TIME -ge $MAX_WAIT_TIME ]; then
            echo "Warning: Root application did not sync within $MAX_WAIT_TIME seconds"
            echo "Current status:"
            argocd app get root-app || true
            echo "Continuing with deployment..."
          fi

          echo "ArgoCD setup complete!"
          echo "Access ArgoCD at: http://$ARGOCD_SERVER"
          echo "Username: admin"
          echo "Password: $ARGOCD_PASSWORD"

      - name: Wait for Applications to Deploy and Apply Final Configurations
        run: |
          # Get Azure parameters from terraform outputs
          AZURE_CLIENT_ID="${{ needs.terraform.outputs.azure_client_id }}"
          AZURE_TENANT_ID="${{ needs.terraform.outputs.azure_tenant_id }}"
          KEYVAULT_NAME="${{ needs.terraform.outputs.keyvault_name }}"
          
          echo "Waiting for ArgoCD applications to deploy..."
          
          # Wait for all applications to be synced and healthy
          argocd app list
          
          # Wait for specific applications to be healthy
          echo "Waiting for applications to be healthy..."
          argocd app wait superset-app --timeout 300 || echo "Superset app not ready yet, continuing..."
          argocd app wait nifi-app --timeout 300 || echo "NiFi app not ready yet, continuing..."
          argocd app wait kobotoolbox-app --timeout 300 || echo "KoboToolbox app not ready yet, continuing..."
          argocd app wait postgresql-app --timeout 300 || echo "PostgreSQL app not ready yet, continuing..."
          argocd app wait monitoring --timeout 300 || echo "Monitoring app not ready yet, continuing..."
          argocd app wait joget-app --timeout 300 || echo "Joget app not ready yet, continuing..."
          
          echo "Applications deployment phase complete. Now applying SecretProviderClass manifests with Azure parameters..."
          
          # Create temporary directory for updated manifests
          mkdir -p /tmp/updated-manifests
          
          # Function to update and apply SecretProviderClass files
          update_secret_provider_class() {
            local file=$1
            local namespace=$2
            local max_retries=5
            local retry_count=0
            
            echo "Processing SecretProviderClass for namespace: $namespace"
            
            # Create updated manifest with Azure parameters
            sed "s/useVMManagedIdentity: \"true\"/clientID: \"$AZURE_CLIENT_ID\"\n    tenantId: \"$AZURE_TENANT_ID\"\n    keyvaultName: \"$KEYVAULT_NAME\"\n    useVMManagedIdentity: \"true\"/" $file > /tmp/updated-manifests/$(basename $file)
            
            # Apply with retry logic
            while [ $retry_count -lt $max_retries ]; do
              if kubectl apply -f /tmp/updated-manifests/$(basename $file) -n $namespace; then
                echo " SecretProviderClass applied successfully for namespace: $namespace"
                return 0
              else
                echo " Failed to apply SecretProviderClass for namespace $namespace, retrying... (attempt $((retry_count + 1))/$max_retries)"
                sleep 10
                retry_count=$((retry_count + 1))
              fi
            done
            
            echo " Failed to apply SecretProviderClass for namespace $namespace after $max_retries attempts"
            return 1
          }
          
          # Update and apply each SecretProviderClass
          update_secret_provider_class "manifests/superset/secret-provider-class.yaml" "superset"
          update_secret_provider_class "manifests/nifi/secret-provider-class.yaml" "nifi-prod"
          update_secret_provider_class "manifests/kobotoolbox/secret-provider-class.yaml" "kobotoolbox"
          update_secret_provider_class "manifests/monitoring/secret-provider-class.yaml" "monitoring"
          
          # Handle Joget deployment with embedded SecretProviderClass
          echo "Updating and applying Joget deployment with SecretProviderClass..."
          sed "s/useVMManagedIdentity: \"true\"/clientID: \"$AZURE_CLIENT_ID\"\n        tenantId: \"$AZURE_TENANT_ID\"\n        keyvaultName: \"$KEYVAULT_NAME\"\n        useVMManagedIdentity: \"true\"/" manifests/joget/joget-deployement.yaml > /tmp/updated-manifests/joget-deployement.yaml
          
          # Apply Joget deployment with retry
          retry_count=0
          max_retries=5
          while [ $retry_count -lt $max_retries ]; do
            if kubectl apply -f /tmp/updated-manifests/joget-deployement.yaml -n joget; then
              echo " Joget deployment with SecretProviderClass applied successfully"
              break
            else
              echo " Failed to apply Joget deployment, retrying... (attempt $((retry_count + 1))/$max_retries)"
              sleep 10
              retry_count=$((retry_count + 1))
            fi
          done
          
          echo "SecretProviderClass manifests application complete. Now patching ServiceAccounts..."
          
          # Function to patch ServiceAccount with retry logic
          patch_service_account() {
            local sa_name=$1
            local namespace=$2
            local max_retries=10
            local retry_count=0
            
            while [ $retry_count -lt $max_retries ]; do
              if kubectl get serviceaccount $sa_name -n $namespace >/dev/null 2>&1; then
                echo " Patching ServiceAccount: $sa_name in namespace: $namespace"
                kubectl patch serviceaccount $sa_name -n $namespace -p "{\"metadata\":{\"annotations\":{\"azure.workload.identity/client-id\":\"$AZURE_CLIENT_ID\"}}}"
                return 0
              else
                echo " ServiceAccount $sa_name not found in namespace $namespace, waiting... (attempt $((retry_count + 1))/$max_retries)"
                sleep 15
                retry_count=$((retry_count + 1))
              fi
            done
            
            echo " Failed to find ServiceAccount $sa_name in namespace $namespace after $max_retries attempts"
            return 1
          }
          
          # Patch each ServiceAccount with retry logic
          patch_service_account "superset-workload-identity" "superset"
          patch_service_account "nifi-workload-identity" "nifi-prod"
          patch_service_account "kobotoolbox-workload-identity" "kobotoolbox"
          patch_service_account "postgresql-workload-identity" "joget"
          patch_service_account "monitoring-workload-identity" "monitoring"
          patch_service_account "joget-workload-identity" "joget"
          
          echo "All ServiceAccounts patched successfully with workload identity!"
          
          # Clean up temporary files
          rm -rf /tmp/updated-manifests
          
          # Trigger a final refresh of all applications to pick up all changes
          echo "Final refresh of applications to pick up all changes..."
          argocd app sync superset-app --timeout 120 || echo "Superset sync completed with warnings"
          argocd app sync nifi-app --timeout 120 || echo "NiFi sync completed with warnings"
          argocd app sync kobotoolbox-app --timeout 120 || echo "KoboToolbox sync completed with warnings"
          argocd app sync postgresql-app --timeout 120 || echo "PostgreSQL sync completed with warnings"
          argocd app sync monitoring --timeout 120 || echo "Monitoring sync completed with warnings"
          argocd app sync joget-app --timeout 120 || echo "Joget sync completed with warnings"
          
          echo " All applications configured successfully with workload identity and SecretProviderClass!"

  terraform-destroy:
    name: "Terraform Destroy"
    if: github.event.inputs.destroy == 'true'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Azure Login (OIDC)
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Terraform Init
        working-directory: ./terraform
        run: |
          terraform init \
            -backend-config="resource_group_name=${{ secrets.TF_STATE_RG }}" \
            -backend-config="storage_account_name=${{ secrets.TF_STATE_SA }}" \
            -backend-config="container_name=tfstate" \
            -backend-config="key=${{ env.TF_VAR_environment }}.terraform.tfstate"

      - name: Terraform Destroy
        working-directory: ./terraform
        run: terraform destroy -auto-approve